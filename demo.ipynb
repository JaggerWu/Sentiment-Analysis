{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This analysis process for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "\n",
    "from sentiment.utilities import dataset_split\n",
    "from sentiment.utilities import load_data\n",
    "from sentiment.utilities import text2vec\n",
    "from sentiment.utilities import y_trainable\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "# Preprocess and convert words and bigrams to integer IDs\n",
    "# We're using the 20000 most frequent words and 20000 most frequent bigrams\n",
    "# from the IMDB dataset here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "X = text2vec(data.text)\n",
    "y = data.ratings.values * 10\n",
    "\n",
    "z = data.reviewers.values\n",
    "\n",
    "idc_all = dataset_split(y, holdout=0.3, validation=0.0)\n",
    "\n",
    "X_train = X[idc_all[0]]\n",
    "y_train_origin = y[idc_all[0]]\n",
    "y_train = y_trainable(y_train_origin)\n",
    "\n",
    "X_val = X[idc_all[1]]\n",
    "y_val_origin = y[idc_all[1]]\n",
    "y_val = y_trainable(y_val_origin)\n",
    "\n",
    "data_test = load_data(category='test')\n",
    "X_test = text2vec(data_test.text)\n",
    "y_test_origin = data_test.ratings.values * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1:SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14337662337662338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sentiment.utilities import mean_absolute_error\n",
    "\n",
    "clf_1 = SVC(C = 2, probability = True)\n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "y_val_predicted = clf_1.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15410199556541021"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_1.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2:Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2257316017316017"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_2 = GaussianNB()\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "y_val_predicted = clf_2.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24223946784922396"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_2.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 3:Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13045887445887444"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_3 = RandomForestClassifier(min_samples_leaf = 3, n_estimators = 100)\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "y_val_predicted = clf_3.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16363636363636364"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_3.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4:BernoulliRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -22.14, time = 0.54s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -25.52, time = 0.74s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.67, time = 0.74s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -19.14, time = 0.73s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -27.89, time = 0.74s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -22.97, time = 0.76s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -34.20, time = 1.36s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -17.95, time = 0.91s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -15.79, time = 0.94s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -18.57, time = 1.35s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -27.72, time = 1.11s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -30.97, time = 0.68s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -32.23, time = 0.67s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.77, time = 0.67s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.86, time = 0.66s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -17.07, time = 0.66s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.01, time = 0.68s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -18.60, time = 0.81s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -23.72, time = 0.86s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.64, time = 0.87s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -23.92, time = 0.78s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -23.73, time = 0.82s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.86, time = 1.04s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.66, time = 0.83s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm = BernoulliRBM(random_state = 0, verbose = True)\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "rbm.learning_rate = 0.07\n",
    "rbm.n_iter = 50\n",
    "# more components tend to give better prediction performance, but larger fitting time\n",
    "rbm.n_components = 800\n",
    "rbm.batch_size = 10\n",
    "logistic.C = 10000.0\n",
    "\n",
    "clf_4 = Pipeline(steps = [('rbm', rbm), ('logistic', logistic)])\n",
    "clf_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted = clf_4.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = clf_4.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
