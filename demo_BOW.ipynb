{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This analysis process for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "\n",
    "from sentiment.utilities import dataset_split\n",
    "from sentiment.utilities import load_data\n",
    "from sentiment.utilities import texts_to_sequences\n",
    "from sentiment.utilities import y_trainable\n",
    "from sentiment.utilities import mean_absolute_error\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "# Preprocess and convert words and bigrams to integer IDs\n",
    "# We're using the 20000 most frequent words and 20000 most frequent bigrams\n",
    "# from the IMDB dataset here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "X = texts_to_sequences(data.text)\n",
    "y = data.ratings.values * 10\n",
    "\n",
    "z = data.reviewers.values\n",
    "\n",
    "idc_all = dataset_split(y, holdout=0.3, validation=0.0)\n",
    "\n",
    "X_train = X[idc_all[0]]\n",
    "y_train_origin = y[idc_all[0]]\n",
    "y_train = y_trainable(y_train_origin)\n",
    "\n",
    "X_val = X[idc_all[1]]\n",
    "y_val_origin = y[idc_all[1]]\n",
    "y_val = y_trainable(y_val_origin)\n",
    "\n",
    "data_test = load_data(category='test')\n",
    "X_test = texts_to_sequences(data_test.text)\n",
    "y_test_origin = data_test.ratings.values * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1:SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_1 = SVC(C = 2, probability = True)\n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf_1, 'w2v_clf/SVM.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = joblib.load('w2v_clf/SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0055500000000000002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_1.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14095238095238097"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_1.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15410199556541021"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_1.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2:Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_2 = GaussianNB()\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf_2, 'w2v_clf/NB.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = joblib.load('w2v_clf/NB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2292642857142857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_2.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25761038961038962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_2.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26862527716186252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_2.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 3:Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_3 = RandomForestClassifier(min_samples_leaf = 3, n_estimators = 100)\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf_3, 'w2v_clf/RF.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = joblib.load('w2v_clf/RF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0055500000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_3.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15903030303030305"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_3.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18514412416851442"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_3.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4:BernoulliRBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm = BernoulliRBM(random_state = 0, verbose = True)\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "rbm.learning_rate = 0.07\n",
    "rbm.n_iter = 50\n",
    "# more components tend to give better prediction performance, but larger fitting time\n",
    "rbm.n_components = 800\n",
    "rbm.batch_size = 10\n",
    "logistic.C = 10000.0\n",
    "\n",
    "clf_4 = Pipeline(steps = [('rbm', rbm), ('logistic', logistic)])\n",
    "clf_4.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf_4, 'w2v_clf/RBM.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4 = joblib.load('w2v_clf/RBM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14632857142857142"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_4.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14346320346320349"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_4.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15410199556541021"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_4.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
