{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This analysis process for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "\n",
    "from sentiment.utilities import dataset_split\n",
    "from sentiment.utilities import load_data\n",
    "from sentiment.utilities import texts_to_sequences\n",
    "from sentiment.utilities import y_trainable\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "# Preprocess and convert words and bigrams to integer IDs\n",
    "# We're using the 20000 most frequent words and 20000 most frequent bigrams\n",
    "# from the IMDB dataset here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "X = texts_to_sequences(data.text)\n",
    "y = data.ratings.values * 10\n",
    "\n",
    "z = data.reviewers.values\n",
    "\n",
    "idc_all = dataset_split(y, holdout=0.3, validation=0.0)\n",
    "\n",
    "X_train = X[idc_all[0]]\n",
    "y_train_origin = y[idc_all[0]]\n",
    "y_train = y_trainable(y_train_origin)\n",
    "\n",
    "X_val = X[idc_all[1]]\n",
    "y_val_origin = y[idc_all[1]]\n",
    "y_val = y_trainable(y_val_origin)\n",
    "\n",
    "data_test = load_data(category='test')\n",
    "X_test = texts_to_sequences(data_test.text)\n",
    "y_test_origin = data_test.ratings.values * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1:SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sentiment.utilities import mean_absolute_error\n",
    "\n",
    "clf_1 = SVC(C = 2, probability = True)\n",
    "clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0055500000000000002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_1.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14095238095238097"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_1.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15410199556541021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_1.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2:Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_2 = GaussianNB()\n",
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2292642857142857"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_2.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25761038961038962"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_2.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26862527716186252"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_2.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 3:Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_3 = RandomForestClassifier(min_samples_leaf = 3, n_estimators = 100)\n",
    "clf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0055500000000000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_3.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15903030303030305"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_3.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18514412416851442"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_3.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 4:BernoulliRBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -12246991968.06, time = 5.04s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -24509397304.44, time = 5.29s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -36771802639.02, time = 4.91s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -49034207974.82, time = 5.92s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -61296613310.31, time = 6.59s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -73559018651.70, time = 4.96s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -85821423985.27, time = 4.92s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -98083829321.34, time = 4.93s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -110346234650.00, time = 5.54s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -122608639983.04, time = 4.99s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -134871045323.21, time = 4.99s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -147133450659.64, time = 4.97s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -159395856004.11, time = 4.96s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -171658261334.29, time = 5.09s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -183920666660.71, time = 6.80s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -196183072012.14, time = 7.12s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -208445477344.82, time = 6.40s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -220707882682.86, time = 5.01s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -232970288001.96, time = 5.03s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -245232693369.11, time = 4.96s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -257495098688.93, time = 4.99s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -269757503978.57, time = 4.98s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -282019909364.29, time = 4.96s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -294282314686.79, time = 4.95s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -306544720035.00, time = 5.03s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -318807125366.43, time = 4.96s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -331069530706.43, time = 5.09s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -343331936055.36, time = 5.12s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -355594341386.07, time = 5.05s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -367856746697.14, time = 5.06s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -380119152048.57, time = 5.10s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -392381557380.36, time = 5.13s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -404643962688.57, time = 5.85s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -416906368064.29, time = 6.53s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -429168773391.43, time = 6.57s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -441431178756.79, time = 7.47s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -453693584074.29, time = 5.09s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -465955989411.79, time = 5.00s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -478218394723.93, time = 4.99s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -490480800086.43, time = 5.03s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -502743205399.29, time = 4.98s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -515005610750.00, time = 4.98s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -527268016102.14, time = 4.99s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -539530421410.71, time = 5.01s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -551792826753.57, time = 5.04s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -564055232119.29, time = 5.00s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -576317637448.57, time = 5.02s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -588580042775.00, time = 4.99s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -600842448133.57, time = 4.98s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -613104853430.00, time = 5.11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.07, n_components=800, n_iter=50,\n",
       "       random_state=0, verbose=True)), ('logistic', LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm = BernoulliRBM(random_state = 0, verbose = True)\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "rbm.learning_rate = 0.07\n",
    "rbm.n_iter = 50\n",
    "# more components tend to give better prediction performance, but larger fitting time\n",
    "rbm.n_components = 800\n",
    "rbm.batch_size = 10\n",
    "logistic.C = 10000.0\n",
    "\n",
    "clf_4 = Pipeline(steps = [('rbm', rbm), ('logistic', logistic)])\n",
    "clf_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14632857142857142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predicted = clf_4.predict(X_train)\n",
    "mean_absolute_error(y_train_origin, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14346320346320349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted = clf_4.predict(X_val)\n",
    "mean_absolute_error(y_val_origin, y_val_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15410199556541021"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted = clf_4.predict(X_test)\n",
    "mean_absolute_error(y_test_origin, y_test_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
